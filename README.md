# HANSON-Python-Portfolio

This is a Portfolio for my notable data science projects!


## Overview
Welcome to the **Portfolio**! This project demonstrates a comprehensive workflow for data analysis, including data cleaning, exploratory data analysis (EDA), model building, and visualization. The goal is to create clean, well-structured datasets, analyze the data to uncover insights, and build predictive models. Additionally, it features a **Streamlit** app for interactive data exploration and presentation and a **Tidy Data** project.

---

## Project Structure

- ğŸ“„ **`README.md`**: Provides an overview of the project, its structure, and setup instructions.

- ğŸ“š **`Harry Potter Named Entity Recognition (NER) App`**
  
ğŸ”— Link to project: ([[https://github.com/ahanson-3/HANSON-Python-Portfolio/tree/main/NERStreamlitApp])

ğŸ”— Link to web app: ([https://hanson-python-portfolio-ev34yf2jhxjcpfcbuuyymc.streamlit.app/])

This interactive Streamlit app demonstrates Named Entity Recognition (NER) using the first chapter of Harry Potter and the Sorcerer's Stone. It uses the spaCy NLP library to identify and classify entities like people, locations, and dates in the text. The app also allows users to input their own text and explore how NLP models recognize entities in new contexts.

*Key Features:*

ğŸ§™â€â™‚ï¸ Preloaded Harry Potter text for automatic NER
âœï¸ Custom user input box to try your own text
ğŸ§  Entity label explanations for learning and context
ğŸ“Š Frequency tables and displaCy visualizations for deeper analysis

*Why It Matters:*

This project highlights my growing skill set in Natural Language Processing, interactive app development with Streamlit, and data presentation. It complements the rest of my portfolio by showing:
1. Proficiency in working with real-world unstructured data (text)
2. Understanding of NLP concepts like tokenization and named entity recognition
3. Experience building interactive, educational tools that explain technical concepts to users



- ğŸ§¹ **`TidyData-Project`**: Contains scripts for **data cleaning** and ensuring the dataset is in a tidy format for analysis. The notebook within the folder performs data cleaning and visualization on a dataset of Olympic medalists
    - Link to project:  ([https://github.com/ahanson-3/HANSON-Python-Portfolio/tree/5ecce32fc09b15f40ab4b33d577e1cdafca938db/TidyData-Project])
    - This project showcases my ability to apply data cleaning, transformation, and visualization techniques using Python. It highlights key skills that are essential for data analysis and machine learning, including:
    1. Tidy Data Principles â€“ Demonstrating an understanding of structured, well-organized datasets for effective analysis.
Data Wrangling with Pandas â€“ Cleaning, reshaping, and handling missing data in real-world datasets.
    2. Exploratory Data Analysis (EDA) â€“ Using visualizations (bar plots, heatmaps, count plots) to uncover patterns and insights.
    3. Aggregation & Pivot Tables â€“ Summarizing data efficiently to derive meaningful conclusions.
    4. Reproducibility & Documentation â€“ Writing clean, well-documented code and explanations, making the project accessible to others.

- ğŸŒ **`basic_streamlit-app`**: A basic **Streamlit** app that allows for interactive data visualization and exploration. This app focuses on Palmer Penguin data and allows you to filter to explore different results.
    - Link to project:  ([https://github.com/ahanson-3/HANSON-Python-Portfolio/tree/5ecce32fc09b15f40ab4b33d577e1cdafca938db/TidyData-Project](https://github.com/ahanson-3/HANSON-Python-Portfolio/tree/5ecce32fc09b15f40ab4b33d577e1cdafca938db/basic_streamlit-app))

- ğŸ” **`EDA`**: Scripts and notebooks for performing **exploratory data analysis** to understand the datasetâ€™s structure, trends, and relationships.

- ğŸ¤– **`Models`**: Includes scripts for building **predictive models** using the cleaned data to generate insights or make predictions.

- ğŸ¨ **`Visualizations`**: Scripts that generate **visualizations** to help interpret the results and communicate findings effectively.
